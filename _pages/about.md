---
layout: single
title: "Rongkun Zhou"
permalink: /
author_profile: true
---

<!-- ===== Self Summary ===== -->
**About Me**  
I'm Rongkun Zhou, a Master's student in Computer Science at Johns Hopkins University, broadly interested in natural language processing and machine learning, especially the reasoning capabilities and factual consistency of large language models.  
My current focus is on improving the faithfulness, explainability, and robustness of NLP systems in tasks like question answering, retrieval, and reasoning over structured data.  
I aim to develop models that generate not only fluent responses but also outputs grounded in knowledge sources and reliable in real-world scenarios.

---

## ğŸ“ Education
- **Johns Hopkins University** â€” M.S. in Computer Science *(Expected Dec 2025)*  
- **University of Minnesota â€“ Twin Cities** â€” B.S. in Mathematics, Minor in Computer Science & Statistics *(Sept 2020 â€“ Dec 2023)*

---

## ğŸ”¬ Ongoing Research <a id="ongoing"></a>
<em>More projects on the <a href="/research-experience/">Research Experience</a> page.</em>

### ğŸ§  Reasoning over Tabular Data  
**Research Assistant Â· Prof. Philipp Koehn**  
*Johns Hopkins University â€” 2024.07â€“Present*  
Exploring how large language models perform structured reasoning over table data.  
We aim to develop and evaluate methods that improve the reliability, transparency, and factual grounding of model-generated reasoning traces in tabular QA tasks.

---

### ğŸ® Debugging Reasoning Failures in Text-Based Games  
**Research Assistant Â· Prof. Ziang Xiao**  
*Johns Hopkins University â€” 2024.08â€“Present*  
Working on the TALES dataset and using the MindCoder framework to investigate where language agents fail to reason effectively during interactive fiction scenarios.  
This project identifies reasoning bottlenecks and stuck states by querying model trajectories and responses, with the goal of guiding model behavior through targeted interventions and improving agent robustness.

---

### ğŸ” Detecting Steganography in LLM Chain-of-Thought  
**Research Assistant Â· William Walden**  
*HLTCOE, Johns Hopkins University â€” 2024.05â€“Present*  
Investigating how reasoning traces in LLM outputs might covertly encode information (textual steganography).  
This project aims to detect and mitigate hidden signals that may enable malicious coordination or model misuse, focusing on interventions aligned with knowledge distillation and output control.
